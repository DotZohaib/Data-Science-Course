{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d10ede98",
   "metadata": {},
   "source": [
    "<h1>In the tech and AI world, \n",
    "CNN stands for Convolutional Neural Network — a deep learning \n",
    "algorithm primarily used in image recognition and computer vision tasks. Key Points: Purpose: Processes and recognizes patterns in visual data</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59d8490f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking dataset structure...\n",
      "Dataset path: F:\\All My Website using Next.js code\\Machine Language\\Data Science\\CNN\n",
      "✅ Path exists: F:\\All My Website using Next.js code\\Machine Language\\Data Science\\CNN\n",
      "📁 Found subdirectories: ['cat', 'dog', 'lion']\n",
      "  📸 cat: 4 images\n",
      "  📸 dog: 4 images\n",
      "  📸 lion: 4 images\n",
      "🔢 Total images found: 12\n",
      "\n",
      "🏗️ Building CNN model...\n",
      "📊 Model summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,539</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_12 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m62\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_12 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_13 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m29\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_13 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_14 (\u001b[38;5;33mMaxPooling2D\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_4 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │     \u001b[38;5;34m2,359,808\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │         \u001b[38;5;34m1,539\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,454,595</span> (9.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,454,595\u001b[0m (9.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,454,595</span> (9.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,454,595\u001b[0m (9.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Creating data generators...\n",
      "🔄 Creating training generator...\n",
      "Found 6 images belonging to 3 classes.\n",
      "✅ Training generator created successfully!\n",
      "   📸 Training samples: 6\n",
      "   📁 Classes found: ['cat', 'dog', 'lion']\n",
      "   🎯 Class indices: {'cat': 0, 'dog': 1, 'lion': 2}\n",
      "\n",
      "🔄 Creating validation generator...\n",
      "Found 0 images belonging to 3 classes.\n",
      "✅ Validation generator created successfully!\n",
      "   📸 Validation samples: 0\n",
      "❌ Error creating data generators: Validation generator has 0 samples!\n",
      "\n",
      "🔍 Debugging information:\n",
      "Directory contents: ['cat', 'dog', 'lion']\n",
      "\n",
      "🔄 Trying without validation split...\n",
      "Found 6 images belonging to 3 classes.\n",
      "✅ Simple generator works! Found 6 samples\n",
      "\n",
      "🧪 Testing generators...\n",
      "Getting a batch from training generator...\n",
      "✅ Successfully got batch: X shape (6, 64, 64, 3), Y shape (6, 3)\n",
      "   🎯 Batch size: 6\n",
      "   📊 X range: [0.000, 1.000]\n",
      "   📊 Y sample: [0. 1. 0.]\n",
      "\n",
      "🚀 Starting training...\n",
      "Epoch 1/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5s/step - accuracy: 0.1667 - loss: 1.0927WARNING:tensorflow:5 out of the last 7 calls to <function TensorFlowTrainer._make_function.<locals>.multi_step_on_iterator at 0x00000279D0DEA340> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 0.1667 - loss: 1.0927 - val_accuracy: 0.3333 - val_loss: 1.0756\n",
      "Epoch 2/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 215ms/step - accuracy: 0.3333 - loss: 1.0404 - val_accuracy: 1.0000 - val_loss: 1.0164\n",
      "Epoch 3/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 185ms/step - accuracy: 0.5000 - loss: 1.0658 - val_accuracy: 0.6667 - val_loss: 0.9876\n",
      "Epoch 4/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 193ms/step - accuracy: 0.6667 - loss: 0.9616 - val_accuracy: 0.6667 - val_loss: 0.9409\n",
      "Epoch 5/5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 197ms/step - accuracy: 0.3333 - loss: 1.0950 - val_accuracy: 0.6667 - val_loss: 0.8951\n",
      "\n",
      "🎉 Training completed successfully!"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final training accuracy: 0.3333\n",
      "Final validation accuracy: 0.6667\n",
      "💾 Model saved to: F:\\All My Website using Next.js code\\Machine Language\\Data Science\\CNN\\cnn_model.h5\n",
      "\n",
      "🔮 Testing prediction on a sample...\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 576ms/step\n",
      "✅ Prediction test successful!\n",
      "   🎯 Predicted: dog (confidence: 0.507)\n",
      "   ✅ Actual: dog\n",
      "\n",
      "✨ Script completed!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 🔹 Dataset path\n",
    "dataset_path = r\"F:\\All My Website using Next.js code\\Machine Language\\Data Science\\CNN\"\n",
    "\n",
    "print(\"🔍 Checking dataset structure...\")\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "# 🔹 Function to check and display folder structure\n",
    "def check_dataset_structure(path):\n",
    "    \"\"\"Check and display the dataset folder structure\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        print(f\"❌ Path does not exist: {path}\")\n",
    "        return False, None\n",
    "    \n",
    "    print(f\"✅ Path exists: {path}\")\n",
    "    \n",
    "    # List all subdirectories\n",
    "    subdirs = [d for d in os.listdir(path) if os.path.isdir(os.path.join(path, d))]\n",
    "    print(f\"📁 Found subdirectories: {subdirs}\")\n",
    "    \n",
    "    # Count images in each subdirectory\n",
    "    image_extensions = ['.jpg', '.jpeg', '.png', '.bmp', '.gif']\n",
    "    class_counts = {}\n",
    "    total_images = 0\n",
    "    \n",
    "    for subdir in subdirs:\n",
    "        subdir_path = os.path.join(path, subdir)\n",
    "        image_count = 0\n",
    "        \n",
    "        for ext in image_extensions:\n",
    "            pattern = os.path.join(subdir_path, f\"*{ext}\")\n",
    "            image_count += len(glob.glob(pattern))\n",
    "            pattern = os.path.join(subdir_path, f\"*{ext.upper()}\")\n",
    "            image_count += len(glob.glob(pattern))\n",
    "        \n",
    "        class_counts[subdir] = image_count\n",
    "        total_images += image_count\n",
    "        print(f\"  📸 {subdir}: {image_count} images\")\n",
    "    \n",
    "    print(f\"🔢 Total images found: {total_images}\")\n",
    "    \n",
    "    if total_images == 0:\n",
    "        print(\"❌ No images found in any subdirectory!\")\n",
    "        return False, None\n",
    "    \n",
    "    return True, class_counts\n",
    "\n",
    "# 🔹 Check the dataset\n",
    "has_data, class_counts = check_dataset_structure(dataset_path)\n",
    "\n",
    "if not has_data:\n",
    "    print(\"\\n🚨 DATASET ISSUE DETECTED!\")\n",
    "    print(\"\\n📋 Expected folder structure:\")\n",
    "    print(\"CNN/\")\n",
    "    print(\"├── dog/\")\n",
    "    print(\"│   ├── image1.jpg\")\n",
    "    print(\"│   ├── image2.jpg\")\n",
    "    print(\"│   └── ...\")\n",
    "    print(\"├── cat/\")\n",
    "    print(\"│   ├── image1.jpg\")\n",
    "    print(\"│   └── ...\")\n",
    "    print(\"└── lion/\")\n",
    "    print(\"    ├── image1.jpg\")\n",
    "    print(\"    └── ...\")\n",
    "    print(\"\\n💡 Make sure:\")\n",
    "    print(\"1. Your images are in the correct folders\")\n",
    "    print(\"2. Images have valid extensions (.jpg, .jpeg, .png, .bmp, .gif)\")\n",
    "    print(\"3. Folder names match your class names\")\n",
    "    exit()\n",
    "\n",
    "# 🔹 Create sample dataset if needed\n",
    "def create_sample_dataset():\n",
    "    \"\"\"Create a sample dataset for testing\"\"\"\n",
    "    print(\"\\n🔧 Would you like to create a sample dataset for testing? (y/n)\")\n",
    "    response = input().lower().strip()\n",
    "    \n",
    "    if response == 'y':\n",
    "        try:\n",
    "            import numpy as np\n",
    "            from PIL import Image\n",
    "            \n",
    "            # Create sample images\n",
    "            classes = ['dog', 'cat', 'lion']\n",
    "            samples_per_class = 50\n",
    "            \n",
    "            for class_name in classes:\n",
    "                class_dir = os.path.join(dataset_path, class_name)\n",
    "                os.makedirs(class_dir, exist_ok=True)\n",
    "                \n",
    "                for i in range(samples_per_class):\n",
    "                    # Create random colored image\n",
    "                    img_array = np.random.randint(0, 256, (128, 128, 3), dtype=np.uint8)\n",
    "                    img = Image.fromarray(img_array)\n",
    "                    img.save(os.path.join(class_dir, f'{class_name}_{i:03d}.jpg'))\n",
    "                \n",
    "                print(f\"✅ Created {samples_per_class} sample images for {class_name}\")\n",
    "            \n",
    "            print(\"🎉 Sample dataset created successfully!\")\n",
    "            return True\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"❌ PIL not installed. Install it with: pip install Pillow\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error creating sample dataset: {e}\")\n",
    "            return False\n",
    "    \n",
    "    return False\n",
    "\n",
    "# If no data found, offer to create sample dataset\n",
    "if sum(class_counts.values()) < 10:  # Less than 10 total images\n",
    "    print(\"⚠️ Very few images found. This might not be enough for training.\")\n",
    "    if create_sample_dataset():\n",
    "        # Recheck after creating sample data\n",
    "        has_data, class_counts = check_dataset_structure(dataset_path)\n",
    "\n",
    "# 🔹 CNN Model (simplified for testing)\n",
    "print(\"\\n🏗️ Building CNN model...\")\n",
    "cnn = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64, 64, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(class_counts), activation='softmax')  # Dynamic number of classes\n",
    "])\n",
    "\n",
    "cnn.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print(\"📊 Model summary:\")\n",
    "cnn.summary()\n",
    "\n",
    "# 🔹 Create data generators with extensive debugging\n",
    "print(\"\\n📊 Creating data generators...\")\n",
    "\n",
    "# Training data generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# 🔹 Try to create generators with error handling\n",
    "try:\n",
    "    print(\"🔄 Creating training generator...\")\n",
    "    train_set = train_datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=16,  # Smaller batch size for testing\n",
    "        class_mode='categorical',\n",
    "        subset='training',\n",
    "        shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Training generator created successfully!\")\n",
    "    print(f\"   📸 Training samples: {train_set.samples}\")\n",
    "    print(f\"   📁 Classes found: {list(train_set.class_indices.keys())}\")\n",
    "    print(f\"   🎯 Class indices: {train_set.class_indices}\")\n",
    "    \n",
    "    print(\"\\n🔄 Creating validation generator...\")\n",
    "    val_set = train_datagen.flow_from_directory(\n",
    "        dataset_path,\n",
    "        target_size=(64, 64),\n",
    "        batch_size=16,\n",
    "        class_mode='categorical',\n",
    "        subset='validation',\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    print(f\"✅ Validation generator created successfully!\")\n",
    "    print(f\"   📸 Validation samples: {val_set.samples}\")\n",
    "    \n",
    "    # Check if generators have data\n",
    "    if train_set.samples == 0:\n",
    "        raise ValueError(\"Training generator has 0 samples!\")\n",
    "    if val_set.samples == 0:\n",
    "        raise ValueError(\"Validation generator has 0 samples!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error creating data generators: {e}\")\n",
    "    print(\"\\n🔍 Debugging information:\")\n",
    "    print(f\"Directory contents: {os.listdir(dataset_path)}\")\n",
    "    \n",
    "    # Try without validation split\n",
    "    print(\"\\n🔄 Trying without validation split...\")\n",
    "    try:\n",
    "        simple_datagen = ImageDataGenerator(rescale=1./255)\n",
    "        simple_generator = simple_datagen.flow_from_directory(\n",
    "            dataset_path,\n",
    "            target_size=(64, 64),\n",
    "            batch_size=16,\n",
    "            class_mode='categorical',\n",
    "            shuffle=True\n",
    "        )\n",
    "        print(f\"✅ Simple generator works! Found {simple_generator.samples} samples\")\n",
    "        \n",
    "        # Use simple generator for both train and val (not ideal but for testing)\n",
    "        train_set = simple_generator\n",
    "        val_set = simple_generator\n",
    "        \n",
    "    except Exception as e2:\n",
    "        print(f\"❌ Simple generator also failed: {e2}\")\n",
    "        exit()\n",
    "\n",
    "# 🔹 Test the generators by getting a batch\n",
    "print(\"\\n🧪 Testing generators...\")\n",
    "try:\n",
    "    print(\"Getting a batch from training generator...\")\n",
    "    batch_x, batch_y = next(train_set)\n",
    "    print(f\"✅ Successfully got batch: X shape {batch_x.shape}, Y shape {batch_y.shape}\")\n",
    "    print(f\"   🎯 Batch size: {len(batch_x)}\")\n",
    "    print(f\"   📊 X range: [{batch_x.min():.3f}, {batch_x.max():.3f}]\")\n",
    "    print(f\"   📊 Y sample: {batch_y[0]}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error getting batch: {e}\")\n",
    "    exit()\n",
    "\n",
    "# 🔹 Train the model\n",
    "print(\"\\n🚀 Starting training...\")\n",
    "try:\n",
    "    # Use fewer epochs for initial testing\n",
    "    history = cnn.fit(\n",
    "        train_set,\n",
    "        epochs=5,  # Start with fewer epochs\n",
    "        validation_data=val_set,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    print(\"\\n🎉 Training completed successfully!\")\n",
    "    print(f\"Final training accuracy: {history.history['accuracy'][-1]:.4f}\")\n",
    "    print(f\"Final validation accuracy: {history.history['val_accuracy'][-1]:.4f}\")\n",
    "    \n",
    "    # Save the model\n",
    "    model_path = os.path.join(dataset_path, 'cnn_model.h5')\n",
    "    cnn.save(model_path)\n",
    "    print(f\"💾 Model saved to: {model_path}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Training failed: {e}\")\n",
    "    print(\"🔍 This might be due to:\")\n",
    "    print(\"1. Insufficient data\")\n",
    "    print(\"2. Memory issues\")\n",
    "    print(\"3. Incompatible image formats\")\n",
    "\n",
    "# 🔹 Quick prediction test\n",
    "print(\"\\n🔮 Testing prediction on a sample...\")\n",
    "try:\n",
    "    # Get a sample from the generator\n",
    "    test_batch_x, test_batch_y = next(train_set)\n",
    "    prediction = cnn.predict(test_batch_x[:1])  # Predict on first image\n",
    "    predicted_class = list(train_set.class_indices.keys())[prediction.argmax()]\n",
    "    actual_class = list(train_set.class_indices.keys())[test_batch_y[0].argmax()]\n",
    "    \n",
    "    print(f\"✅ Prediction test successful!\")\n",
    "    print(f\"   🎯 Predicted: {predicted_class} (confidence: {prediction.max():.3f})\")\n",
    "    print(f\"   ✅ Actual: {actual_class}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Prediction test failed: {e}\")\n",
    "\n",
    "print(\"\\n✨ Script completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
