{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc6bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 1. Load the data\n",
    "print(\"=== LOADING EMPLOYEE SALARY DATA ===\")\n",
    "data = pd.read_excel(\"dummy_users.xlsx\")  # Update with your file path\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(data.head())\n",
    "\n",
    "# 2. Data Analysis and Preprocessing\n",
    "print(\"\\n=== DATA EXPLORATION ===\")\n",
    "print(f\"Data types:\\n{data.dtypes}\")\n",
    "print(f\"\\nMissing values:\\n{data.isnull().sum()}\")\n",
    "print(f\"\\nTarget variable (salary) statistics:\")\n",
    "print(data['salary'].describe())\n",
    "\n",
    "# Remove unnecessary columns\n",
    "columns_to_drop = ['id', 'name', 'phone_number']\n",
    "available_drops = [col for col in columns_to_drop if col in data.columns]\n",
    "if available_drops:\n",
    "    data = data.drop(columns=available_drops)\n",
    "    print(f\"Dropped columns: {available_drops}\")\n",
    "\n",
    "# 3. Define features and target\n",
    "target = 'salary'\n",
    "X = data.drop(columns=[target])\n",
    "y = data[target]\n",
    "\n",
    "print(f\"\\nFeatures: {list(X.columns)}\")\n",
    "print(f\"Target: {target}\")\n",
    "\n",
    "# 4. Identify categorical and numerical columns\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "print(f\"\\nCategorical features: {categorical_features}\")\n",
    "print(f\"Numerical features: {numerical_features}\")\n",
    "\n",
    "# Show unique values for each categorical feature\n",
    "print(\"\\n=== CATEGORICAL FEATURE ANALYSIS ===\")\n",
    "for col in categorical_features:\n",
    "    unique_vals = X[col].unique()\n",
    "    print(f\"{col}: {len(unique_vals)} unique values -> {list(unique_vals)}\")\n",
    "\n",
    "# 5. Encode categorical variables using LabelEncoder (better for small datasets)\n",
    "print(\"\\n=== ENCODING CATEGORICAL VARIABLES ===\")\n",
    "X_encoded = X.copy()\n",
    "label_encoders = {}\n",
    "\n",
    "for column in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X_encoded[column] = le.fit_transform(X[column])\n",
    "    label_encoders[column] = le\n",
    "    print(f\"Encoded {column}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "\n",
    "# 6. Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = X_encoded.copy()\n",
    "if numerical_features:\n",
    "    X_scaled[numerical_features] = scaler.fit_transform(X_encoded[numerical_features])\n",
    "\n",
    "print(f\"\\nFinal dataset shape: {X_scaled.shape}\")\n",
    "print(\"First 5 rows of processed data:\")\n",
    "print(X_scaled.head())\n",
    "\n",
    "# 7. Handle small dataset - use stratified split based on salary ranges\n",
    "# Create salary bins for stratification\n",
    "y_bins = pd.cut(y, bins=3, labels=['Low', 'Medium', 'High'])\n",
    "print(f\"\\nSalary distribution:\")\n",
    "print(y_bins.value_counts())\n",
    "\n",
    "# Split data with stratification\n",
    "try:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.25, random_state=42, stratify=y_bins\n",
    "    )\n",
    "except:\n",
    "    # If stratification fails, use random split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.25, random_state=42\n",
    "    )\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape}\")\n",
    "print(f\"Test set size: {X_test.shape}\")\n",
    "\n",
    "# 8. Define models suitable for small datasets\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression (Œ±=0.1)': Ridge(alpha=0.1),\n",
    "    'Ridge Regression (Œ±=1.0)': Ridge(alpha=1.0),\n",
    "    'Ridge Regression (Œ±=10.0)': Ridge(alpha=10.0),\n",
    "    'Lasso Regression (Œ±=0.1)': Lasso(alpha=0.1),\n",
    "    'Lasso Regression (Œ±=1.0)': Lasso(alpha=1.0),\n",
    "    'Decision Tree (depth=3)': DecisionTreeRegressor(random_state=42, max_depth=3),\n",
    "    'Decision Tree (depth=5)': DecisionTreeRegressor(random_state=42, max_depth=5),\n",
    "    'Random Forest (10 trees)': RandomForestRegressor(n_estimators=10, random_state=42, max_depth=5),\n",
    "    'Random Forest (50 trees)': RandomForestRegressor(n_estimators=50, random_state=42, max_depth=5),\n",
    "    'K-Nearest Neighbors (k=3)': KNeighborsRegressor(n_neighbors=3),\n",
    "    'K-Nearest Neighbors (k=5)': KNeighborsRegressor(n_neighbors=5),\n",
    "}\n",
    "\n",
    "# 9. Train and evaluate models using Leave-One-Out CV for small dataset\n",
    "print(\"\\n=== TRAINING AND EVALUATING MODELS ===\")\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    try:\n",
    "        # Train model\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # Leave-One-Out Cross-validation for small datasets\n",
    "        loo = LeaveOneOut()\n",
    "        loo_scores = cross_val_score(model, X_scaled, y, cv=loo, scoring='r2')\n",
    "        loo_mean = loo_scores.mean()\n",
    "        loo_std = loo_scores.std()\n",
    "        \n",
    "        results[name] = {\n",
    "            'R¬≤': r2,\n",
    "            'MSE': mse,\n",
    "            'MAE': mae,\n",
    "            'RMSE': rmse,\n",
    "            'LOO_R¬≤_mean': loo_mean,\n",
    "            'LOO_R¬≤_std': loo_std,\n",
    "            'Model': model,\n",
    "            'Predictions': y_pred\n",
    "        }\n",
    "        \n",
    "        print(f\"‚úÖ R¬≤ Score: {r2:.4f}\")\n",
    "        print(f\"   MSE: {mse:.2f}\")\n",
    "        print(f\"   RMSE: {rmse:.2f}\")\n",
    "        print(f\"   MAE: {mae:.2f}\")\n",
    "        print(f\"   Leave-One-Out CV R¬≤: {loo_mean:.4f} (¬±{loo_std:.4f})\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to train {name}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# 10. Compare all models\n",
    "print(\"\\n=== MODEL COMPARISON ===\")\n",
    "if results:\n",
    "    comparison_df = pd.DataFrame({\n",
    "        name: {\n",
    "            'R¬≤': metrics['R¬≤'],\n",
    "            'RMSE': metrics['RMSE'],\n",
    "            'MAE': metrics['MAE'],\n",
    "            'LOO_CV_R¬≤': metrics['LOO_R¬≤_mean']\n",
    "        }\n",
    "        for name, metrics in results.items()\n",
    "    }).T\n",
    "    \n",
    "    comparison_df = comparison_df.sort_values('R¬≤', ascending=False)\n",
    "    print(\"Model Performance (sorted by R¬≤):\")\n",
    "    print(comparison_df.round(4))\n",
    "    \n",
    "    # Get best model\n",
    "    best_model_name = comparison_df.index[0]\n",
    "    best_model = results[best_model_name]['Model']\n",
    "    best_r2 = results[best_model_name]['R¬≤']\n",
    "    \n",
    "    print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "    print(f\"   R¬≤ Score: {best_r2:.4f}\")\n",
    "    print(f\"   RMSE: ${results[best_model_name]['RMSE']:,.2f}\")\n",
    "    print(f\"   Leave-One-Out CV: {results[best_model_name]['LOO_R¬≤_mean']:.4f}\")\n",
    "    \n",
    "    # 11. Feature Importance Analysis\n",
    "    print(f\"\\n=== FEATURE ANALYSIS ===\")\n",
    "    \n",
    "    # For linear models, show coefficients\n",
    "    if hasattr(best_model, 'coef_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': X_scaled.columns,\n",
    "            'Coefficient': best_model.coef_,\n",
    "            'Abs_Coefficient': np.abs(best_model.coef_)\n",
    "        }).sort_values('Abs_Coefficient', ascending=False)\n",
    "        \n",
    "        print(f\"Feature Coefficients ({best_model_name}):\")\n",
    "        print(feature_importance)\n",
    "    \n",
    "    # For tree-based models, show feature importance\n",
    "    elif hasattr(best_model, 'feature_importances_'):\n",
    "        feature_importance = pd.DataFrame({\n",
    "            'Feature': X_scaled.columns,\n",
    "            'Importance': best_model.feature_importances_\n",
    "        }).sort_values('Importance', ascending=False)\n",
    "        \n",
    "        print(f\"Feature Importance ({best_model_name}):\")\n",
    "        print(feature_importance)\n",
    "    \n",
    "    # 12. Detailed Predictions Analysis\n",
    "    print(f\"\\n=== DETAILED PREDICTIONS ANALYSIS ===\")\n",
    "    print(\"Test Set Predictions:\")\n",
    "    test_results = pd.DataFrame({\n",
    "        'Actual': y_test.values,\n",
    "        'Predicted': results[best_model_name]['Predictions'],\n",
    "        'Error': y_test.values - results[best_model_name]['Predictions'],\n",
    "        'Error_%': ((y_test.values - results[best_model_name]['Predictions']) / y_test.values * 100)\n",
    "    })\n",
    "    test_results.index = y_test.index\n",
    "    print(test_results.round(2))\n",
    "    \n",
    "    # 13. Visualizations\n",
    "    print(\"\\n=== CREATING VISUALIZATIONS ===\")\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Actual vs Predicted\n",
    "    y_pred_best = results[best_model_name]['Predictions']\n",
    "    axes[0, 0].scatter(y_test, y_pred_best, alpha=0.8, s=100, color='blue')\n",
    "    axes[0, 0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[0, 0].set_xlabel('Actual Salary ($)')\n",
    "    axes[0, 0].set_ylabel('Predicted Salary ($)')\n",
    "    axes[0, 0].set_title(f'Actual vs Predicted - {best_model_name}')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add point labels\n",
    "    for i, (actual, pred) in enumerate(zip(y_test, y_pred_best)):\n",
    "        axes[0, 0].annotate(f'${actual:,.0f}\\n${pred:,.0f}', \n",
    "                           (actual, pred), xytext=(5, 5), \n",
    "                           textcoords='offset points', fontsize=8)\n",
    "    \n",
    "    # 2. Residuals plot\n",
    "    residuals = y_test - y_pred_best\n",
    "    axes[0, 1].scatter(y_pred_best, residuals, alpha=0.8, s=100, color='green')\n",
    "    axes[0, 1].axhline(y=0, color='r', linestyle='--')\n",
    "    axes[0, 1].set_xlabel('Predicted Salary ($)')\n",
    "    axes[0, 1].set_ylabel('Residuals ($)')\n",
    "    axes[0, 1].set_title('Residual Plot')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Model comparison\n",
    "    model_names = list(comparison_df.index[:8])  # Top 8 models\n",
    "    r2_scores = list(comparison_df['R¬≤'][:8])\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(model_names)))\n",
    "    \n",
    "    bars = axes[1, 0].barh(model_names, r2_scores, color=colors)\n",
    "    axes[1, 0].set_xlabel('R¬≤ Score')\n",
    "    axes[1, 0].set_title('Model Performance Comparison')\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, score in zip(bars, r2_scores):\n",
    "        width = bar.get_width()\n",
    "        axes[1, 0].text(width + 0.01, bar.get_y() + bar.get_height()/2, \n",
    "                       f'{score:.3f}', ha='left', va='center', fontsize=8)\n",
    "    \n",
    "    # 4. Salary distribution\n",
    "    axes[1, 1].hist(y, bins=8, alpha=0.7, color='orange', edgecolor='black')\n",
    "    axes[1, 1].axvline(y.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: ${y.mean():,.0f}')\n",
    "    axes[1, 1].axvline(y.median(), color='blue', linestyle='--', linewidth=2, label=f'Median: ${y.median():,.0f}')\n",
    "    axes[1, 1].set_xlabel('Salary ($)')\n",
    "    axes[1, 1].set_ylabel('Frequency')\n",
    "    axes[1, 1].set_title('Salary Distribution')\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 14. Make predictions on new data example\n",
    "    print(\"\\n=== EXAMPLE PREDICTION ===\")\n",
    "    \n",
    "    # Create a sample new employee (using the same encoding)\n",
    "    sample_data = {\n",
    "        'role': 'Developer',\n",
    "        'age': 35,\n",
    "        'gender': 'Female',\n",
    "        'alive': 'No',\n",
    "        'department': 'IT',\n",
    "        'alone': 'Yes',\n",
    "        'city': 'New York',\n",
    "        'state': 'NY',\n",
    "        'single': 'No'\n",
    "    }\n",
    "    \n",
    "    # Encode the sample data\n",
    "    sample_encoded = {}\n",
    "    for feature, value in sample_data.items():\n",
    "        if feature in categorical_features:\n",
    "            if value in label_encoders[feature].classes_:\n",
    "                sample_encoded[feature] = label_encoders[feature].transform([value])[0]\n",
    "            else:\n",
    "                # Handle unseen category by using the most common category\n",
    "                most_common = X[feature].mode()[0]\n",
    "                sample_encoded[feature] = label_encoders[feature].transform([most_common])[0]\n",
    "                print(f\"Warning: '{value}' not seen in training for {feature}. Using '{most_common}' instead.\")\n",
    "        else:\n",
    "            sample_encoded[feature] = value\n",
    "    \n",
    "    # Scale numerical features\n",
    "    sample_df = pd.DataFrame([sample_encoded])\n",
    "    if numerical_features:\n",
    "        sample_df[numerical_features] = scaler.transform(sample_df[numerical_features])\n",
    "    \n",
    "    predicted_salary = best_model.predict(sample_df)[0]\n",
    "    print(f\"\\nSample Employee Profile:\")\n",
    "    for key, value in sample_data.items():\n",
    "        print(f\"  {key}: {value}\")\n",
    "    print(f\"\\nPredicted Salary: ${predicted_salary:,.2f}\")\n",
    "    \n",
    "    # 15. Final Summary\n",
    "    print(\"\\n=== FINAL SUMMARY ===\")\n",
    "    print(f\"üéØ Dataset: {data.shape[0]} employees with {len(X.columns)} features\")\n",
    "    print(f\"üèÜ Best Model: {best_model_name}\")\n",
    "    print(f\"üìä Performance Metrics:\")\n",
    "    print(f\"   ‚Ä¢ R¬≤ Score: {best_r2:.4f} ({best_r2*100:.1f}% variance explained)\")\n",
    "    print(f\"   ‚Ä¢ RMSE: ${results[best_model_name]['RMSE']:,.2f}\")\n",
    "    print(f\"   ‚Ä¢ MAE: ${results[best_model_name]['MAE']:,.2f}\")\n",
    "    print(f\"   ‚Ä¢ Leave-One-Out CV: {results[best_model_name]['LOO_R¬≤_mean']:.4f}\")\n",
    "    \n",
    "    # Performance interpretation\n",
    "    if best_r2 > 0.8:\n",
    "        print(\"\\n‚úÖ EXCELLENT: Model performance is very good!\")\n",
    "        print(\"   The model explains >80% of salary variance.\")\n",
    "    elif best_r2 > 0.6:\n",
    "        print(\"\\n‚úÖ GOOD: Model performance is acceptable.\")\n",
    "        print(\"   The model explains >60% of salary variance.\")\n",
    "    elif best_r2 > 0.3:\n",
    "        print(\"\\n‚ö†Ô∏è MODERATE: Model performance is moderate.\")\n",
    "        print(\"   Consider feature engineering or more data.\")\n",
    "    else:\n",
    "        print(\"\\n‚ùå POOR: Model performance needs improvement.\")\n",
    "        print(\"   Consider different approach or more data.\")\n",
    "    \n",
    "    # Data insights\n",
    "    print(f\"\\nüí° Key Dataset Insights:\")\n",
    "    print(f\"   ‚Ä¢ Salary range: ${y.min():,} - ${y.max():,}\")\n",
    "    print(f\"   ‚Ä¢ Average salary: ${y.mean():,.0f}\")\n",
    "    print(f\"   ‚Ä¢ Age range: {X['age'].min()}-{X['age'].max()} years\")\n",
    "    print(f\"   ‚Ä¢ Job roles: {len(X['role'].unique())} different roles\")\n",
    "    print(f\"   ‚Ä¢ Departments: {len(X['department'].unique())} departments\")\n",
    "    print(f\"   ‚Ä¢ Locations: {len(X['city'].unique())} cities, {len(X['state'].unique())} states\")\n",
    "    \n",
    "    # Save the best model\n",
    "    import joblib\n",
    "    model_filename = f'best_salary_model_{best_model_name.replace(\" \", \"_\").replace(\"(\", \"\").replace(\")\", \"\").lower()}.pkl'\n",
    "    scaler_filename = 'salary_scaler.pkl'\n",
    "    encoders_filename = 'salary_encoders.pkl'\n",
    "    \n",
    "    joblib.dump(best_model, model_filename)\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    joblib.dump(label_encoders, encoders_filename)\n",
    "    \n",
    "    print(f\"\\nüíæ Model files saved:\")\n",
    "    print(f\"   ‚Ä¢ {model_filename}\")\n",
    "    print(f\"   ‚Ä¢ {scaler_filename}\")\n",
    "    print(f\"   ‚Ä¢ {encoders_filename}\")\n",
    "    \n",
    "    print(\"\\nüöÄ Model is ready for deployment!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No models were successfully trained. Check your data and try again.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
